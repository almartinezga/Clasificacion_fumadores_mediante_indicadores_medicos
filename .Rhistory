})
print(estadisticos_filtrado)
# First rows of filtered data
head(dataset_filtrado)
# Dimensions for filtered data
dim(dataset_filtrado)
#BOXPLOT FOR EACH COLUMN for the filtered data
par(mfrow=c(2, 2)) # Change the number of rows and columns of charts
for (col in colnames(dataset_filtrado)) {
boxplot(dataset_filtrado[[col]], main = col, col = "lightblue", border = "black")
}
# TARGET VARIABLE (INDEPENDENT) as factor
dataset_filtrado$smoking <- as.factor(dataset_filtrado$smoking)
#SMOKING VALUES COUNT (NON-SMOKERS / SMOKERS)
#Data imbalance detected
summary(dataset_filtrado$smoking)
#DATA STANDARDIZATION
# Rescale the variables so that they have a mean of zero and a standard deviation of 1
# Select all columns except 'dental.caries' and 'smoking' (they are already boolean)
columnas_a_mutar <- setdiff(names(dataset_filtrado), c('dental.caries', 'smoking', 'hearing.left.','hearing.right.','Urine.protein'))
# Apply the scale function to the selected columns
dataset_filtrado <- dataset_filtrado %>%
mutate_at(vars(columnas_a_mutar), scale)
# Display the resulting dataset
print(dataset_filtrado)
# Training and test data dimensions
dim(datos_entrenamiento)
#SPLIT TRAINING AND TEST DATA
# Random seed of 2023 for reproducibility
set.seed(2023)
# Training Data - 80%
proporcion_entrenamiento <- 0.8
indice_particion <- createDataPartition(dataset_filtrado$smoking, p = proporcion_entrenamiento, list = FALSE)
datos_entrenamiento <- dataset_filtrado[indice_particion, ] # training 80%
datos_prueba <- dataset_filtrado[-indice_particion, ] # testing 20%
# Training and test data dimensions
dim(datos_entrenamiento)
dim(datos_prueba)
# Confirming there are no null values
sum(is.na(datos_entrenamiento))
sum(is.na(datos_prueba))
# Value counts
summary(datos_entrenamiento$smoking)
# BALANCING TRAINING DATA
# Contar el número de instancias para cada valor de 'smoking'
table(datos_entrenamiento$smoking)
# Realizar submuestreo
set.seed(2023)
datos_entrenamiento_balanceados <- datos_entrenamiento %>%
group_by(smoking) %>%
sample_n(46592) #AQUÍ ES SEGÚN EL NÚMERO DE TRUE Y FALSE QUERRAMOS USAR.
# Verificar el nuevo conteo
table(datos_entrenamiento_balanceados$smoking)
print(datos_entrenamiento_balanceados)
# DECISION TREE MODEL WITH BALANCED DATA
modelo_arbol <- rpart(smoking ~ ., data = datos_entrenamiento_balanceados, method = "class")
predicciones_arbol <- predict(modelo_arbol, datos_prueba,type = "class")
knitr::opts_chunk$set(echo = TRUE)
#install.packages("AER")
#install.packages("ROSE")
install.packages("data.table")
# Loading Libraries
library(dplyr)
library(e1071)
library(ggplot2)
library(ISLR)
library(caret)
# Machine Learning
library(randomForest)
library(AER)
library(readr)
library(rpart)
library(xgboost)
library(ROSE)
library(kknn)
library(data.table)
# Loading the dataset
dataset <- read.csv("Smokers.csv")
View(dataset)
# Dataset summary, after speaking with a domain expert in Health:
# It is necessary to remove some outliers. Not all are impossible values—some may appear under special conditions—but others show inconsistencies (e.g., ALT and GTP) or clear measurement errors (e.g., LDL).
# Eyesight (Vision) – Left & Right
# Measure: Visual sharpness
# Scale: 0 = normal vision (≈20/20), 1 = mild impairment, 2 = moderate impairment.
# The full scale runs 0–9.9 (9.9 = blindness), but only 0–2 appear in this dataset.
# Smoking impact: Increases risk of macular degeneration and cataracts.
# Hearing – Left & Right
# Measure: Hearing ability.
# Scale: 1 = good, 2 = poor.
# Smoking impact: Linked to higher risk of age-related hearing loss.
# Blood Pressure
# Systolic Scale: Normal <120 mm Hg; 120–139 = prehypertension; higher = hypertension.
# Diastolic Scale: Normal <80 mm Hg; 80–89 = prehypertension; higher = hypertension.
# Smoking impact: Temporarily raises blood pressure.
# Fasting Blood Sugar
# Scale: Normal: <100 mg/dL; 100–125 = prediabetes.
# Smoking impact: Increases risk of insulin resistance and type 2 diabetes.
# Cholesterol & Triglycerides
# Total Cholesterol: Normal <200 mg/dL; 200–239 = borderline high.
# Triglycerides: Normal <150 mg/dL; 150–199 = borderline high.
# HDL (good): >60 mg/dL is ideal; <40 = low.
# LDL (bad): Normal <130 mg/dL; >175 = high.
# Smoking impact: Raises LDL & triglycerides, lowers HDL, increases heart disease risk.
# Hemoglobin
# Normal:
# Men: 13.8–17.2 g/dL
# Women: 12.1–15.1 g/dL
# Smoking impact: Reduces oxygen-carrying capacity.
# Urine Protein
# Normal: <150 mg/day. Dataset uses scale (1 = low, 2 = normal, ≥3 = increasing levels).
# Smoking impact: Contributes to kidney disease.
# Serum Creatinine
# Normal:
# Men: 0.6–1.2 mg/dL (slightly higher for older adults)
# Women: 0.5–1.1 mg/dL (slightly higher for older adults)
# Dataset: 0.8–1.7 mg/dL
# Smoking impact: Damages kidney function.
# Liver Enzymes (AST, ALT & GTP)
# Measure: Indicators of liver health.
# Normal: Values vary by lab; elevated levels suggest liver damage.
# AST (Aspartate Aminotransferase): 10 to 40 units per liter (U/L)
# ALT (Alanine Aminotransferase): 7 to 56 U/L
# GTP (Glutamyltransferase): ~9 to 63 U/L
# Smoking impact: Can impair liver function.
# GTP (γ-GTP)
# Normal range: ~9 to 63 U/L (higher values = possible liver damage).
# Smoking impact: Increases risk of liver damage.
# Dental Cavities (dental.caries)
# Dataset scale: 0 = no cavities, 1 = cavities present.
# Smoking impact: Raises risk of periodontal disease and cavities.
# Smoking
# Dataset scale: 0 = does not smoke, 1 = smoker.
dim(dataset)
nombres_columnas <- colnames(dataset)
print(nombres_columnas)
#BODY MASS INDEX
# Calculate the body mass index (BMI) and add it as a new column
dataset$BMI <- dataset$"weight.kg." / ((dataset$"height.cm." / 100)^2)
#REMOVE ID COLUMN (CATEGORICAL VALUE)
dataset <- subset(dataset, select = -c(id,  X, X.1,height.cm.,weight.kg.))
# FIRST ROWS
head(dataset)
# LAST ROWS
tail(dataset)
# FIXING DATA TYPES
dataset$smoking <- as.logical(dataset$smoking)
dataset$dental.caries <- as.logical(dataset$dental.caries)
# STATISTICAL SUMMARY
summary(dataset)
# NULL VALUES. There are no NAs
sum(is.na(dataset))
# UNIQUE VALUES: There are no duplicates
count(unique(dataset))
#Key Stats by columns
estadisticos <- sapply(dataset, function(col) {
c(
Average = mean(col),
Median = median(col),
Min = min(col),
Max = max(col),
Variance = var(col),
Standard_Deviation = sd(col)
)
})
print(estadisticos)
# Identifying outliers
par(mfrow=c(1, 1))
boxplot(dataset, col = "lightblue", border = "black")
par(cex.axis=0.8)
par(las=2)
# Boxplot for each column
par(mfrow=c(2, 2))  # Change the number of rows and columns of charts
for (col in colnames(dataset)) {
boxplot(dataset[[col]], main = col, col = "lightblue", border = "black")
}
# Histogram
par(mfrow=c(2, 2))  # Change the number of rows and columns of charts
num_columnas <- ncol(dataset)
for (i in 1:(num_columnas - 3)) {
col <- colnames(dataset)[i]
hist(dataset[[col]], main = col, xlab = col, col = "lightblue", border = "black")
}
# Correlation Matrix
matriz_correlacion <- cor(dataset)
# HEATMAP
library(corrplot)
corrplot(matriz_correlacion, method = "color")
# DataFrame for not ordinary values
smk_ext <- dataset
# Ranges for each column
rango_waist_cm <- c(45, 100)
rango_systolic <- c(80, 160)
rango_relaxation <- c(50, 100)
rango_fasting_blood_sugar <- c(60, 200)
rango_cholesterol <- c(120, 300)
rango_triglyceride <- c(20, 500)
rango_hdl <- c(25, 100)
rango_ldl <- c(50, 190)
rango_hemoglobin <- c(10, 18)
rango_urine_protein <- c(0, 4)
rango_serum_creatinine <- c(0.5, 2.5)
rango_ast <- c(10, 80)
rango_alt <- c(5, 100)
rango_gtp <- c(10, 80)
# Filter by extreme values
# The dataset is split in two:
# 1. Keeps only extreme values (very high or very low), which may indicate serious health issues or measurement errors.
# 2. Remaining values considered "normal" based on our research with the domain expert
smk_ext <- smk_ext[
(smk_ext$waist.cm. > rango_waist_cm[2] | smk_ext$waist.cm. < rango_waist_cm[1]) |
(smk_ext$systolic > rango_systolic[2] | smk_ext$systolic < rango_systolic[1]) |
(smk_ext$relaxation > rango_relaxation[2] | smk_ext$relaxation < rango_relaxation[1]) |
(smk_ext$fasting.blood.sugar > rango_fasting_blood_sugar[2] | smk_ext$fasting.blood.sugar < rango_fasting_blood_sugar[1]) |
(smk_ext$Cholesterol > rango_cholesterol[2] | smk_ext$Cholesterol < rango_cholesterol[1]) |
(smk_ext$triglyceride > rango_triglyceride[2] | smk_ext$triglyceride < rango_triglyceride[1]) |
(smk_ext$HDL < rango_hdl[1] | smk_ext$HDL > rango_hdl[2]) |
(smk_ext$LDL > rango_ldl[2] | smk_ext$LDL < rango_ldl[1]) |
(smk_ext$hemoglobin > rango_hemoglobin[2] | smk_ext$hemoglobin < rango_hemoglobin[1]) |
(smk_ext$Urine.protein >= rango_urine_protein[2] | smk_ext$Urine.protein < rango_urine_protein[1]) |
(smk_ext$serum.creatinine > rango_serum_creatinine[2] | smk_ext$serum.creatinine < rango_serum_creatinine[1]) |
(smk_ext$AST > rango_ast[2] | smk_ext$AST < rango_ast[1]) |
(smk_ext$ALT > rango_alt[2] | smk_ext$ALT < rango_alt[1]) |
(smk_ext$Gtp > rango_gtp[2] | smk_ext$Gtp < rango_gtp[1]),
]
# Counts extreme values for each column
count_waist_cm <- sum(smk_ext$waist.cm. > rango_waist_cm[2] | smk_ext$waist.cm. < rango_waist_cm[1])
count_systolic <- sum(smk_ext$systolic > rango_systolic[2] | smk_ext$systolic < rango_systolic[1])
count_relaxation <- sum(smk_ext$relaxation > rango_relaxation[2] | smk_ext$relaxation < rango_relaxation[1])
count_fasting_blood_sugar <- sum(smk_ext$fasting.blood.sugar > rango_fasting_blood_sugar[2] | smk_ext$fasting.blood.sugar < rango_fasting_blood_sugar[1])
count_cholesterol <- sum(smk_ext$Cholesterol > rango_cholesterol[2] | smk_ext$Cholesterol < rango_cholesterol[1])
count_triglyceride <- sum(smk_ext$triglyceride > rango_triglyceride[2] | smk_ext$triglyceride < rango_triglyceride[1])
count_hdl <- sum(smk_ext$HDL < rango_hdl[1] | smk_ext$HDL > rango_hdl[2])
count_ldl <- sum(smk_ext$LDL > rango_ldl[2] | smk_ext$LDL < rango_ldl[1])
count_hemoglobin <- sum(smk_ext$hemoglobin > rango_hemoglobin[2] | smk_ext$hemoglobin < rango_hemoglobin[1])
count_urine_protein <- sum(smk_ext$Urine.protein >= rango_urine_protein[2] | smk_ext$Urine.protein < rango_urine_protein[1])
count_serum_creatinine <- sum(smk_ext$serum.creatinine > rango_serum_creatinine[2] | smk_ext$serum.creatinine < rango_serum_creatinine[1])
count_ast <- sum(smk_ext$AST > rango_ast[2] | smk_ext$AST < rango_ast[1])
count_alt <- sum(smk_ext$ALT > rango_alt[2] | smk_ext$ALT < rango_alt[1])
count_gtp <- sum(smk_ext$Gtp > rango_gtp[2] | smk_ext$Gtp < rango_gtp[1])
# Show results
cat("Extreme Values for waist.cm.:", count_waist_cm, "\n")
cat("Extreme Values for systolic:", count_systolic, "\n")
cat("Extreme Values for relaxation:", count_relaxation, "\n")
cat("Extreme Values for fasting.blood.sugar:", count_fasting_blood_sugar, "\n")
cat("Extreme Values for Cholesterol:", count_cholesterol, "\n")
cat("Extreme Values for triglyceride:", count_triglyceride, "\n")
cat("Extreme Values for HDL:", count_hdl, "\n")
cat("Extreme Values for LDL:", count_ldl, "\n")
cat("Extreme Values for hemoglobin:", count_hemoglobin, "\n")
cat("Extreme Values for Urine.protein:", count_urine_protein, "\n")
cat("Extreme Values for serum.creatinine:", count_serum_creatinine, "\n")
cat("Extreme Values for AST:", count_ast, "\n")
cat("Extreme Values for ALT:", count_alt, "\n")
cat("Extreme Values for Gtp:", count_gtp, "\n")
# Normal DataFrame without extreme values
smk_norm <- dataset[!(rownames(dataset) %in% rownames(smk_ext)), ]
View(smk_ext)
View(smk_norm)
dataset_filtrado <- smk_norm
print(dataset_filtrado)
# BOXPLOT for filtered dataset
par(mfrow=c(1, 1))
boxplot(dataset_filtrado, col = "lightblue", border = "black")
par(cex.axis=0.8)
par(las=2)
# STATS ON FILTERED DATA
estadisticos_filtrado <- sapply(dataset_filtrado, function(col) {
c(
Average = mean(col),
Median = median(col),
Min = min(col),
Max = max(col),
Variance = var(col),
Standard_Deviation = sd(col)
)
})
print(estadisticos_filtrado)
# First rows of filtered data
head(dataset_filtrado)
# Dimensions for filtered data
dim(dataset_filtrado)
#BOXPLOT FOR EACH COLUMN for the filtered data
par(mfrow=c(2, 2)) # Change the number of rows and columns of charts
for (col in colnames(dataset_filtrado)) {
boxplot(dataset_filtrado[[col]], main = col, col = "lightblue", border = "black")
}
# TARGET VARIABLE (INDEPENDENT) as factor
dataset_filtrado$smoking <- as.factor(dataset_filtrado$smoking)
#SMOKING VALUES COUNT (NON-SMOKERS / SMOKERS)
#Data imbalance detected
summary(dataset_filtrado$smoking)
#DATA STANDARDIZATION
# Rescale the variables so that they have a mean of zero and a standard deviation of 1
# Select all columns except 'dental.caries' and 'smoking' (they are already boolean)
columnas_a_mutar <- setdiff(names(dataset_filtrado), c('dental.caries', 'smoking', 'hearing.left.','hearing.right.','Urine.protein'))
# Apply the scale function to the selected columns
dataset_filtrado <- dataset_filtrado %>%
mutate_at(vars(columnas_a_mutar), scale)
# Display the resulting dataset
print(dataset_filtrado)
#SPLIT TRAINING AND TEST DATA
# Random seed of 2023 for reproducibility
set.seed(2023)
# Training Data - 80%
proporcion_entrenamiento <- 0.8
indice_particion <- createDataPartition(dataset_filtrado$smoking, p = proporcion_entrenamiento, list = FALSE)
datos_entrenamiento <- dataset_filtrado[indice_particion, ] # training 80%
datos_prueba <- dataset_filtrado[-indice_particion, ] # testing 20%
# Training and test data dimensions
dim(datos_entrenamiento)
dim(datos_prueba)
# Confirming there are no null values
sum(is.na(datos_entrenamiento))
sum(is.na(datos_prueba))
# Value counts: Smoking vs No smoking
summary(datos_entrenamiento$smoking)
# BALANCING TRAINING DATA
# Value counts: Smoking vs No smoking
table(datos_entrenamiento$smoking)
# Subsampling
set.seed(2023)
datos_entrenamiento_balanceados <- datos_entrenamiento %>%
group_by(smoking) %>%
sample_n(46592) # Number of TRUES
# Verifying both are equal after subsampling
table(datos_entrenamiento_balanceados$smoking) # 46592 TRUE, 46592 FALSE
print(datos_entrenamiento_balanceados)
# DECISION TREE MODEL WITH BALANCED DATA
modelo_arbol <- rpart(smoking ~ ., data = datos_entrenamiento_balanceados, method = "class")
predicciones_arbol <- predict(modelo_arbol, datos_prueba,type = "class")
# CONFUSION MATRIX: DECISION TREE WITH BALANCED DATA
verdaderos <- datos_prueba$smoking
predicciones <- predicciones_arbol
mc <- confusionMatrix(predicciones, verdaderos)
print(mc)
# DECISION TREE VISUALIZATION: BALANCED DATA
library(rpart)
library(rpart.plot)
rpart.plot(modelo_arbol)
# CONFUSION MATRIX: DECISION TREE WITHOUT BALANCING THE DATA
modelo_arbol <- rpart(smoking ~ ., data = datos_entrenamiento, method = "class")
predicciones_arbol <- predict(modelo_arbol, datos_prueba,type = "class")
# CONFUSION MATRIX: DECISION TREE WITHOUT BALANCING DATA
verdaderos <- datos_prueba$smoking
predicciones <- predicciones_arbol
mc <- confusionMatrix(predicciones, verdaderos)
print(mc)
# DECISION TREE VISUALIZATION: WITHOUT BALANCING THE DATA
library(rpart)
library(rpart.plot)
rpart.plot(modelo_arbol)
# XGBOOST 1
# Converting to matrix (required by the model)
matriz = model.matrix(smoking ~ . -1, data = dataset_filtrado)
set.seed(2023)
trainIndex <-createDataPartition(dataset_filtrado$smoking, p = proporcion_entrenamiento,
list = FALSE, times = 1)
# Training matrix, y for training; Test matrix and y for testing
matriz_train <- matriz[trainIndex,]
y_train = dataset_filtrado$smoking[trainIndex]
y_train_numeric <- as.numeric(as.factor(y_train)) - 1
matriz_test <- matriz[-trainIndex,]
y_test = dataset_filtrado$smoking[-trainIndex]
y_test_numeric <- as.numeric(as.factor(y_test)) - 1
# Deploying the model
modelo_xgboost <- xgboost(data = matriz_train, max.depth = 8, eta = 1, nthread = 2,
label = y_train_numeric, nrounds = 100, objective = "binary:logistic",
eval.metric='logloss', verbose = 1)
#XGBOOST CONFUSION MATRIX 1
# Convert classifications to factor (0, 1)
predicciones_xgboost <- predict(modelo_xgboost, matriz_test)
pred_xgboost <- as.numeric(predicciones_xgboost > 0.5)
# Convert to factors
pred_xgboost <- as.factor(pred_xgboost)
y_test <- as.factor(y_test)
# Ensure both have the same levels
levels(pred_xgboost) <- levels(y_test)
# Confusion Matrix
mc_xgboost <- confusionMatrix(pred_xgboost, y_test)
print(mc_xgboost)
# FEATURE IMPORTANCE: XGBOOST 1
importance <- xgb.importance(feature_names = colnames(matriz_train), model = modelo_xgboost)
head(importance, n= 10)
xgb.plot.importance(importance_matrix = importance)
# CROSS VALIDATION XGBOOST 1
xgb.fit1 <- xgb.cv(
data = matriz_train,
label = y_train_numeric,
nrounds = 100,
eval.metric = 'logloss',
max.depth = 8,
eta = 1,
nfold = 5,
objective = "binary:logistic",
verbose = 0
)
xgb.fit1$evaluation_log
ggplot(xgb.fit1$evaluation_log) +
geom_line(aes(iter, train_logloss_mean), color= "red") +
geom_line(aes(iter, test_logloss_mean), color= "blue")
# IMPROVING XGBOOST1
xgb.fit <- xgb.cv(
data = matriz_train,
label = y_train_numeric,
eval.metric = 'logloss',
objective = "binary:logistic",
nfold = 10,
max.depth = 8,
eta = 0.06,
nthread= 5,
subsample= 1,
colsample_bytree= 0.5,
lambda= 0.5,
alpha= 0.5,
min_child_weight= 3,
nrounds = 125,
)
xgb.fit$evaluation_log
ggplot(xgb.fit$evaluation_log) +
geom_line(aes(iter, train_logloss_mean), color= "red") +
geom_line(aes(iter, test_logloss_mean), color= "blue")
# XGBOOST 2 MODEL WITHOUT DATA BALANCING
xgb.2 <- xgboost(data = matriz_train,
max.depth = 8,
eta = 0.06,
nthread = 5,
label = y_train_numeric,
nrounds = 125,
objective = "binary:logistic",
colsample_bytree= 0.5,
lambda= 0.5,
alpha= 0.5,
min_child_weight= 3,
eval.metric='logloss',
verbose = 1)
# Convert classifications to factor (0, 1)
predicciones_xgb.2 <- predict(xgb.2, matriz_test)
pred_xgb.2 <- as.numeric(predicciones_xgb.2 > 0.5)
# Convert to factors
pred_xgb.2 <- as.factor(pred_xgb.2)
y_test <- as.factor(y_test)
# Ensure both have the same levels
levels(pred_xgb.2) <- levels(y_test)
# Confusion Matrix
mc_xgb.2 <- confusionMatrix(pred_xgb.2, y_test)
print(mc_xgb.2)
# Confusion matrix with precision and recall
mc_xgb.2 <- confusionMatrix(pred_xgb.2, y_test, mode = "prec_recall")
print(mc_xgb.2)
# FEATURE IMPORTANCE: XGBOOST 2 WITHOUT BALANCING THE DATA
importance <- xgb.importance(feature_names = colnames(matriz_train), model = xgb.2)
head(importance, n= 10)
xgb.plot.importance(importance_matrix = importance)
# XGBOOST 2 WITH BALANCED DATA
# Training matrix, and training, test and test matrix
matriz_train <- model.matrix(smoking ~ . -1, data = datos_entrenamiento_balanceados)
y_train = datos_entrenamiento_balanceados$smoking
y_train_numeric <- as.numeric(as.factor(y_train)) - 1
matriz_test <- model.matrix(smoking ~ . -1, data = datos_prueba)
y_test = datos_prueba$smoking
y_test_numeric <- as.numeric(as.factor(y_test)) - 1
# Creating the XGBOOST 2 Model
xgb.3 <- xgboost(data = matriz_train,
max.depth = 8,
eta = 0.06,
nthread = 5,
label = y_train_numeric,
nrounds = 125,
objective = "binary:logistic",
colsample_bytree= 0.5,
lambda= 0.5,
alpha= 0.5,
min_child_weight= 3,
eval.metric='logloss',
verbose = 1)
# Convert classifications to factor (0, 1)
predicciones_xgb.3 <- predict(xgb.3, matriz_test)
pred_xgb.3 <- as.numeric(predicciones_xgb.3 > 0.5)
# Convert to factors
pred_xgb.3 <- as.factor(pred_xgb.3)
y_test <- as.factor(y_test)
# Ensure both have the same levels
levels(pred_xgb.3) <- levels(y_test)
# Confusion Matrix
mc_xgb.3 <- confusionMatrix(pred_xgb.3, y_test)
print(mc_xgb.3)
# KNN without data balancing
modelo_knn <- train.kknn(smoking ~ ., data = datos_entrenamiento)
predicciones_knn <- predict(modelo_knn, datos_prueba)
# CONFUSION MATRIX: KNN WITHOUT DATA BALANCING
verdaderos <-datos_prueba$smoking
predicciones <- predicciones_knn
mc <-confusionMatrix(predicciones, verdaderos)
print(mc)
# KNN WITH BALANCED DATA
modelo_knn_bal <- train.kknn(smoking ~ ., data = datos_entrenamiento_balanceados)#, kmax = 2)
predicciones_knn_bal <- predict(modelo_knn_bal, datos_prueba)
# CONFUSION MATRIX: KNN WITH BALANCED DATA
verdaderos_knn_bal <-datos_prueba$smoking
predicciones_knn_bal <- predicciones_knn_bal
mc <-confusionMatrix(predicciones_knn_bal, verdaderos_knn_bal)
print(mc)
dataset_filtrado <- smk_norm
#DATA STANDARDIZATION
# Rescale the variables so that they have a mean of zero and a standard deviation of 1
# Select all columns except 'dental.caries' and 'smoking' (they are already boolean)
columnas_a_mutar <- setdiff(names(dataset_filtrado), c('dental.caries', 'smoking', 'hearing.left.','hearing.right.','Urine.protein'))
# Apply the scale function to the selected columns
dataset_filtrado <- dataset_filtrado %>%
mutate_at(vars(columnas_a_mutar), scale)
# Display the resulting dataset
# print(dataset_filtrado)
